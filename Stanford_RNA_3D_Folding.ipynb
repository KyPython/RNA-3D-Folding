{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOax1OKvfgMhMMbpTeXTmOX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyPython/RNA-3D-Folding/blob/main/Stanford_RNA_3D_Folding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Requirements & Installs/Imports***"
      ],
      "metadata": {
        "id": "DNiJ-RWaoVe5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Y6cKVdm8j4",
        "outputId": "2ca9f655-3cbb-48ff-cd19-24d528e8fe45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Stanford RNA 3D Folding\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Stanford RNA 3D Folding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj-NF_qdz7Ai",
        "outputId": "82c59704-8a1c-4e80-81c0-6b171cd3b72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr  9 17:58:20 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0             28W /   70W |     258MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requirements File"
      ],
      "metadata": {
        "id": "idK5fz8Dopqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('requirements.txt', 'a') as f:\n",
        "        f.write('\\n')  # Add to requirements.txt'''"
      ],
      "metadata": {
        "collapsed": true,
        "id": "27DVdzt7oosl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Cached Dependencies"
      ],
      "metadata": {
        "id": "31FcRhPBQWuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "#!mkdir -p /content/drive/MyDrive/colab_packages\n",
        "# Target directory for installation\n",
        "target_dir = '/content/drive/MyDrive/colab_packages'\n",
        "\n",
        "# Ensure target directory exists\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Install packages with --target\n",
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html --target=\"{target_dir}\"\n",
        "sys.path.append(target_dir)\n",
        "!pip install --upgrade cupy-cuda12x\n",
        "!pip install --extra-index-url https://pypi.nvidia.com cudf-cu12 rmm\n",
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ],
      "metadata": {
        "id": "CyA5Ui0GQJT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reinstall Dependencies (If Needed)"
      ],
      "metadata": {
        "id": "dbyrZLt6QZn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"Is CUDA available? {torch.cuda.is_available()}\")\n",
        "!pip install --upgrade pip\n",
        "!pip install --target=/content/drive/MyDrive/colab_packages -r /content/drive/MyDrive/Stanford\\ RNA\\ 3D\\ Folding/requirements.txt\n",
        "!pip uninstall -y torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9GZJ5FUGqmrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA Version:\", torch.version.cuda)\n",
        "print(\"Torch Version:\", torch.__version__)\n",
        "!nvcc --version\n",
        "\n",
        "!pip install openmm\n",
        "!pip install dask[distributed] cupy dask-cuda\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import torch.nn as nn\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from transformers import BertModel, BertTokenizer, EsmModel, EsmTokenizer\n",
        "from torch.optim import Adam\n",
        "import torch.optim as optim # Correct way to import optim if needed for general operations.\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from openmm import app, LangevinIntegrator, Platform\n",
        "from openmm import unit as omm_unit\n",
        "from openmm.openmm import *\n",
        "from itertools import product\n",
        "from IPython.display import display\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display, HTML\n",
        "import cudf\n",
        "import cupy as cp #Make sure this is run in a cell before this code\n",
        "import rmm\n",
        "\n",
        "print(\"cuDF version:\", cudf.__version__)\n",
        "print(\"CuPy version:\", cp.__version__) # Refer to cupy with the alias you gave in the import, cp.\n",
        "print(\"RMM version:\", rmm.__version__)\n",
        "print(\"Torch Geometric Version:\", torch_geometric.__version__)"
      ],
      "metadata": {
        "id": "6ncMPnPG4HvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***RNA Sequence Encoding***"
      ],
      "metadata": {
        "id": "tCVMukE8dv77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNA Sequence Encoding Methods Functions"
      ],
      "metadata": {
        "id": "qSPePN_3o7Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load RNA sequences from dataset files\n",
        "def load_rna_sequences(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df['sequence'].dropna().tolist()  # Drop missing values and return as a list\n",
        "\n",
        "# 1. One-Hot Encoding\n",
        "def one_hot_encode(seq):\n",
        "    mapping = {'A': [1, 0, 0, 0], 'U': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'C': [0, 0, 0, 1]}\n",
        "    return np.array([mapping[base] for base in seq if base in mapping])\n",
        "\n",
        "# 2. Integer Encoding\n",
        "def integer_encode(seq):\n",
        "    mapping = {'A': 0, 'U': 1, 'G': 2, 'C': 3}\n",
        "    return [mapping[base] for base in seq if base in mapping]\n",
        "\n",
        "# 3. k-mer Encoding (k=2)\n",
        "def kmer_encode(seq, k=2):\n",
        "    kmers = [''.join(kmer) for kmer in product('AUGC', repeat=k)]\n",
        "    mapping = {kmer: i for i, kmer in enumerate(kmers)}\n",
        "    return [mapping[seq[i:i+k]] for i in range(len(seq) - k + 1) if seq[i:i+k] in mapping]\n",
        "\n",
        "# 4. Word Embedding using Torch (Random Initialization)\n",
        "def get_word_embedding(seq, embedding_dim=4):\n",
        "    vocab = {'A': 0, 'U': 1, 'G': 2, 'C': 3}\n",
        "    indices = torch.tensor([vocab[base] for base in seq if base in vocab])\n",
        "    embedding_layer = torch.nn.Embedding(num_embeddings=4, embedding_dim=embedding_dim)\n",
        "    return embedding_layer(indices)\n",
        "\n",
        "# 5. Positional Encoding (Transformer-style)\n",
        "def positional_encoding(seq_length, d_model=4):\n",
        "    \"\"\"\n",
        "    Computes positional encoding using sine and cosine functions.\n",
        "\n",
        "    Args:\n",
        "        seq_length (int): Length of the sequence.\n",
        "        d_model (int): Dimension of the model.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Positional encoding matrix of shape (seq_length, d_model).\n",
        "    \"\"\"\n",
        "\n",
        "    positions = np.arange(seq_length)[:, np.newaxis]\n",
        "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
        "    pe = np.zeros((seq_length, d_model))\n",
        "    pe[:, 0::2] = np.sin(positions * div_term)\n",
        "    pe[:, 1::2] = np.cos(positions * div_term)\n",
        "    return pe"
      ],
      "metadata": {
        "id": "bFHpy517c1TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNA Sequence Encoding Execution"
      ],
      "metadata": {
        "id": "y2bMtNhIc1BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to dataset files (Update these with actual file locations)\n",
        "train_file = \"/content/drive/MyDrive/Stanford RNA 3D Folding/Stanford_Data/train_sequences.csv\"\n",
        "validation_file = \"/content/drive/MyDrive/Stanford RNA 3D Folding/Stanford_Data/validation_sequences.csv\"\n",
        "test_file = \"/content/drive/MyDrive/Stanford RNA 3D Folding/Stanford_Data/test_sequences.csv\"\n",
        "\n",
        "# Load RNA sequences\n",
        "train_sequences = load_rna_sequences(train_file)\n",
        "validation_sequences = load_rna_sequences(validation_file)\n",
        "test_sequences = load_rna_sequences(test_file)\n",
        "\n",
        "# Select a sample RNA sequence for encoding (first one from train set)\n",
        "rna_sequence = train_sequences[0] if train_sequences else \"AUGC\"\n",
        "\n",
        "integer_encoded = integer_encode(rna_sequence)\n",
        "print(\"\\nInteger Encoding:\", integer_encoded)\n",
        "\n",
        "kmer_encoded = kmer_encode(rna_sequence, k=2)\n",
        "print(\"\\nk-mer Encoding:\", kmer_encoded)\n",
        "\n",
        "word_embedding = get_word_embedding(rna_sequence)\n",
        "print(\"\\nWord Embedding:\\n\", word_embedding)\n",
        "\n",
        "# --- Execute the encoding methods after defining them ---\n",
        "\n",
        "one_hot_encoded = one_hot_encode(rna_sequence)\n",
        "\n",
        "integer_encoded = integer_encode(rna_sequence)\n",
        "print(\"\\nInteger Encoding:\", integer_encoded)\n",
        "\n",
        "kmer_encoded = kmer_encode(rna_sequence, k=2)\n",
        "print(\"\\nk-mer Encoding:\", kmer_encoded)\n",
        "\n",
        "word_embedding = get_word_embedding(rna_sequence)\n",
        "print(\"\\nWord Embedding:\\n\", word_embedding)\n",
        "\n",
        "# Example usage:\n",
        "pos_encoding = positional_encoding(len(rna_sequence))\n",
        "\n",
        "# Print the full positional encoding\n",
        "np.set_printoptions(threshold=np.inf)  # Print the full array\n",
        "print(\"\\nPositional Encoding:\\n\", pos_encoding)\n",
        "\n",
        "# Convert the NumPy array to an HTML table for display\n",
        "html_table = pd.DataFrame(pos_encoding).to_html(index=False)\n",
        "\n",
        "# Display the HTML table in Jupyter Notebook\n",
        "display(HTML(html_table))"
      ],
      "metadata": {
        "id": "MBjngew6o75L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***3D Structural Data***"
      ],
      "metadata": {
        "id": "LVKku-t-dsZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3D Structural Data for Model Training Functions"
      ],
      "metadata": {
        "id": "B55sgDD1o9le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cudf\n",
        "import cupy as cp\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_3d_structure(file_path, n_samples=1000, chunk_size=5000):  # Reduced chunk size\n",
        "    \"\"\"Load 3D structure data using cuDF in chunks manually.\"\"\"\n",
        "    # Initialize an empty cuDF DataFrame to store the concatenated data\n",
        "    df = cudf.DataFrame()\n",
        "\n",
        "    # Read the CSV in chunks with Pandas, convert to cuDF, and concatenate\n",
        "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
        "        df_chunk = cudf.DataFrame.from_pandas(chunk)\n",
        "        df = cudf.concat([df, df_chunk], ignore_index=True)\n",
        "        if len(df) > 100000:  # Optional: Stop once you have enough data\n",
        "            break\n",
        "\n",
        "    # Sample n_samples random rows from the DataFrame\n",
        "    if n_samples < len(df):\n",
        "        df = df.sample(n=n_samples, random_state=42)  # Set random_state for reproducibility\n",
        "\n",
        "    # Extract relevant columns (residue ID & 3D coordinates)\n",
        "    coords_columns = [col for col in df.columns if col.startswith((\"x_\", \"y_\", \"z_\"))]\n",
        "\n",
        "    # Fill NaN values with 0 before converting to NumPy\n",
        "    coords = df[coords_columns].fillna(0).to_numpy()\n",
        "\n",
        "    return coords\n",
        "\n",
        "# Normalize coordinates (mean-centered)\n",
        "def normalize_coordinates(coords):\n",
        "    return coords - np.mean(coords, axis=0)\n",
        "\n",
        "# Compute pairwise distances using cuPy on GPU in smaller batches\n",
        "def compute_pairwise_distances_gpu(coords, batch_size=500):  # Reduce batch size\n",
        "    \"\"\"Compute pairwise distances using cuPY on the GPU in smaller batches.\"\"\"\n",
        "    coords_gpu = cp.asarray(coords)  # Move data to GPU\n",
        "    n = coords_gpu.shape[0]\n",
        "\n",
        "    # Initialize an empty list to store the distance matrix chunks\n",
        "    distance_matrix_chunks = []\n",
        "\n",
        "    # Process data in batches\n",
        "    for i in range(0, n, batch_size):\n",
        "        batch_i = coords_gpu[i: min(i + batch_size, n)]\n",
        "\n",
        "        # Reduce batch size further if needed\n",
        "        if batch_i.shape[0] * coords_gpu.shape[0] > 1000000:  # Adjust based on memory availability\n",
        "            smaller_batch_size = 1000000 // coords_gpu.shape[0]\n",
        "            batch_i = batch_i[:smaller_batch_size]\n",
        "\n",
        "        # Compute pairwise distances for the current batch\n",
        "        distances_batch = cp.linalg.norm(batch_i[:, None, :] - coords_gpu[None, :, :], axis=2)\n",
        "        distance_matrix_chunks.append(distances_batch)\n",
        "\n",
        "    # Concatenate the chunks to get the full distance matrix\n",
        "    distances_gpu = cp.concatenate(distance_matrix_chunks, axis=0)\n",
        "\n",
        "    # Reduce precision to float16 if needed (optional for memory optimization)\n",
        "    # distances_gpu = distances_gpu.astype(cp.float16)\n",
        "\n",
        "    return cp.asnumpy(distances_gpu)  # Transfer results back to CPU"
      ],
      "metadata": {
        "id": "5Yo9QwScdOQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3D Structural Data Execution"
      ],
      "metadata": {
        "id": "_x0AyYLvdN1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the GPU visibility (use GPU with index 0)\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# Print versions\n",
        "print(\"RMM version:\", rmm.__version__)\n",
        "print(\"cuDF version:\", cudf.__version__)\n",
        "print(\"cuPY version:\", cp.__version__)\n",
        "\n",
        "# File path for the 3D structure data\n",
        "train_labels_file = \"/content/drive/MyDrive/Stanford RNA 3D Folding/Stanford_Data/train_labels.csv\"\n",
        "\n",
        "\n",
        "# Load XYZ coordinates with reduced chunk size\n",
        "xyz_coords = load_3d_structure(train_labels_file)\n",
        "print(\"Raw XYZ Coordinates:\\n\", xyz_coords[:5])  # Show first 5 residues\n",
        "\n",
        "normalized_coords = normalize_coordinates(xyz_coords)\n",
        "print(\"\\nNormalized Coordinates:\\n\", normalized_coords[:5])\n",
        "\n",
        "# Compute pairwise distance matrix\n",
        "distance_matrix = compute_pairwise_distances_gpu(normalized_coords)\n",
        "print(\"\\nPairwise Distance Matrix:\\n\", distance_matrix[:5, :5])\n",
        "\n",
        "# Convert to PyTorch tensor for deep learning models\n",
        "xyz_tensor = torch.tensor(normalized_coords, dtype=torch.float32)\n",
        "distance_tensor = torch.tensor(distance_matrix, dtype=torch.float32)\n",
        "\n",
        "print(\"\\nXYZ Tensor Shape:\", xyz_tensor.shape)\n",
        "print(\"Distance Tensor Shape:\", distance_tensor.shape)"
      ],
      "metadata": {
        "id": "6URGf8HdpA1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8dc277-234d-4ba5-e225-c3ad38331168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMM version: 25.02.00\n",
            "cuDF version: 25.02.01\n",
            "cuPY version: 13.4.1\n",
            "Raw XYZ Coordinates:\n",
            " [[228.73199463 321.70901489 172.67500305]\n",
            " [301.00698853 128.70399475 220.96000671]\n",
            " [ 63.47200012  37.36800003  54.69800186]\n",
            " [-17.12899971 -55.125       -8.89900017]\n",
            " [ 13.08500004  -5.24599981 -45.72700119]]\n",
            "\n",
            "Normalized Coordinates:\n",
            " [[ 186.76339866  272.71260091  107.9527409 ]\n",
            " [ 259.03839255   79.70758076  156.23774456]\n",
            " [  21.50340415  -11.62841396  -10.02426029]\n",
            " [ -59.09759568 -104.12141399  -73.62126232]\n",
            " [ -28.88359593  -54.2424138  -110.44926334]]\n",
            "\n",
            "Pairwise Distance Matrix:\n",
            " [[  0.         211.67440592 349.39841346 485.20163021 448.44469377]\n",
            " [211.67440592   0.         303.98715253 433.40370253 414.68498005]\n",
            " [349.39841346 303.98715253   0.         138.18847599 120.1664845 ]\n",
            " [485.20163021 433.40370253 138.18847599   0.          68.97174856]\n",
            " [448.44469377 414.68498005 120.1664845   68.97174856   0.        ]]\n",
            "\n",
            "XYZ Tensor Shape: torch.Size([1000, 3])\n",
            "Distance Tensor Shape: torch.Size([1000, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Feature Engineering***"
      ],
      "metadata": {
        "id": "lvGtsoG5dpE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering Functions"
      ],
      "metadata": {
        "id": "MM0L41qwpFZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate base-pairing map from dot-bracket notation\n",
        "def dot_bracket_to_matrix(structure):\n",
        "    stack = []\n",
        "    matrix = np.zeros((len(structure), len(structure)), dtype=np.float32)\n",
        "\n",
        "    for i, char in enumerate(structure):\n",
        "        if char == '(':\n",
        "            stack.append(i)\n",
        "        elif char == ')':\n",
        "            j = stack.pop()\n",
        "            matrix[i, j] = matrix[j, i] = 1  # Symmetric pairing\n",
        "    return matrix\n",
        "\n",
        "# Function to compute nucleotide frequencies\n",
        "def compute_nucleotide_frequencies(sequence):\n",
        "    counts = {base: sequence.count(base) for base in 'AUGC'}\n",
        "    total = len(sequence)\n",
        "    return {base: count / total for base, count in counts.items()}\n",
        "\n",
        "# Function to generate k-mer embeddings (k=2 for simplicity)\n",
        "def kmer_encoding(sequence, k=2):\n",
        "    kmers = [''.join(kmer) for kmer in product('AUGC', repeat=k)]\n",
        "    mapping = {kmer: i for i, kmer in enumerate(kmers)}\n",
        "    return [mapping[sequence[i:i+k]] for i in range(len(sequence) - k + 1)]"
      ],
      "metadata": {
        "id": "ReyNzgGNddjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering Execution"
      ],
      "metadata": {
        "id": "itfFKWS9ddLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample RNA secondary structure (Dot-Bracket Notation)\n",
        "sample_sequence = \"AUGCUAGC\"\n",
        "sample_structure = \"..((..))\"  # Example: Paired bases are indicated by ( )\n",
        "\n",
        "# Generate base-pairing interaction matrix\n",
        "pairing_matrix = dot_bracket_to_matrix(sample_structure)\n",
        "print(\"Base-Pairing Interaction Matrix:\\n\", pairing_matrix)\n",
        "\n",
        "nucleotide_freqs = compute_nucleotide_frequencies(sample_sequence)\n",
        "print(\"\\nNucleotide Frequencies:\", nucleotide_freqs)\n",
        "\n",
        "kmer_encoded = kmer_encoding(sample_sequence, k=2)\n",
        "print(\"\\nk-mer Encoding:\", kmer_encoded)\n",
        "\n",
        "# Convert base-pairing matrix to PyTorch tensor\n",
        "pairing_tensor = torch.tensor(pairing_matrix, dtype=torch.float32)\n",
        "print(\"\\nPairing Tensor Shape:\", pairing_tensor.shape)"
      ],
      "metadata": {
        "id": "SowkgquepDFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b9f7ce-305e-4213-9a19-ccf9bcc3aa3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base-Pairing Interaction Matrix:\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "\n",
            "Nucleotide Frequencies: {'A': 0.25, 'U': 0.25, 'G': 0.25, 'C': 0.25}\n",
            "\n",
            "k-mer Encoding: [1, 6, 11, 13, 4, 2, 11]\n",
            "\n",
            "Pairing Tensor Shape: torch.Size([8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Structural Information***"
      ],
      "metadata": {
        "id": "rV8f5XBvd2fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Structural Information for Prediction Accuracy Functions"
      ],
      "metadata": {
        "id": "vUu3YaKJpHIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate base-pairing map from dot-bracket notation (GPU version)\n",
        "def dot_bracket_to_matrix_gpu(structure):\n",
        "    stack = []\n",
        "    n = len(structure)\n",
        "    matrix = cp.zeros((n, n), dtype=cp.float32)  # Create matrix on GPU\n",
        "\n",
        "    for i, char in enumerate(structure):\n",
        "        if char == '(':\n",
        "            stack.append(i)\n",
        "        elif char == ')':\n",
        "            j = stack.pop()\n",
        "            matrix[i, j] = matrix[j, i] = 1  # Symmetric pairing\n",
        "    return matrix\n",
        "\n",
        "# Function to compute nucleotide frequencies (GPU version)\n",
        "def compute_nucleotide_frequencies_gpu(sequence):\n",
        "    counts = {base: sequence.count(base) for base in 'AUGC'}\n",
        "    total = len(sequence)\n",
        "    freqs = {base: count / total for base, count in counts.items()}\n",
        "    return freqs\n",
        "\n",
        "# Function to generate k-mer embeddings (GPU version, k=2 for simplicity)\n",
        "def kmer_encoding_gpu(sequence, k=2):\n",
        "    kmers = [''.join(kmer) for kmer in product('AUGC', repeat=k)]\n",
        "    mapping = {kmer: i for i, kmer in enumerate(kmers)}\n",
        "    return [mapping[sequence[i:i+k]] for i in range(len(sequence) - k + 1)]"
      ],
      "metadata": {
        "id": "z3igKQFbd8hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Structural Information Execution"
      ],
      "metadata": {
        "id": "NdjmtEIkd8xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the GPU visibility (use GPU with index 0)\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# Print versions\n",
        "print(\"RMM version:\", rmm.__version__)\n",
        "print(\"cuDF version:\", cudf.__version__)\n",
        "print(\"cuPY version:\", cp.__version__)\n",
        "\n",
        "# Sample RNA secondary structure (Dot-Bracket Notation)\n",
        "sample_sequence = \"AUGCUAGC\"\n",
        "sample_structure = \"..((..))\"  # Example: Paired bases are indicated by ( )\n",
        "\n",
        "# Generate base-pairing interaction matrix on GPU\n",
        "pairing_matrix_gpu = dot_bracket_to_matrix_gpu(sample_structure)\n",
        "print(\"Base-Pairing Interaction Matrix (GPU):\\n\", pairing_matrix_gpu)\n",
        "\n",
        "nucleotide_freqs = compute_nucleotide_frequencies_gpu(sample_sequence)\n",
        "print(\"\\nNucleotide Frequencies:\", nucleotide_freqs)\n",
        "\n",
        "kmer_encoded = kmer_encoding_gpu(sample_sequence, k=2)\n",
        "print(\"\\nk-mer Encoding:\", kmer_encoded)\n",
        "\n",
        "# Convert base-pairing matrix to PyTorch tensor on GPU\n",
        "pairing_tensor_gpu = torch.tensor(pairing_matrix_gpu.get(), dtype=torch.float32).cuda()  # Move to GPU\n",
        "print(\"\\nPairing Tensor Shape (GPU):\", pairing_tensor_gpu.shape)\n"
      ],
      "metadata": {
        "id": "IaAkzFuTpJ7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f11f2ac6-bbf9-4d63-c121-adadc582f3cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMM version: 25.02.00\n",
            "cuDF version: 25.02.01\n",
            "cuPY version: 13.4.1\n",
            "Base-Pairing Interaction Matrix (GPU):\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "\n",
            "Nucleotide Frequencies: {'A': 0.25, 'U': 0.25, 'G': 0.25, 'C': 0.25}\n",
            "\n",
            "k-mer Encoding: [1, 6, 11, 13, 4, 2, 11]\n",
            "\n",
            "Pairing Tensor Shape (GPU): torch.Size([8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Load & process RNA Data***"
      ],
      "metadata": {
        "id": "say_DalleHlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load & Process RNA Data Functions"
      ],
      "metadata": {
        "id": "hqjGjTLleJ5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import signal\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "from numba import cuda\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "# Create a mapping using a dictionary (instead of a cupy.ndarray)\n",
        "base_mapping_num = {\n",
        "    ord('A'): 0,\n",
        "    ord('C'): 1,\n",
        "    ord('G'): 2,\n",
        "    ord('T'): 3,\n",
        "}\n",
        "\n",
        "# Define base_mapping for CPU processing\n",
        "base_mapping = {\n",
        "    'A': 0,\n",
        "    'C': 1,\n",
        "    'G': 2,\n",
        "    'T': 3,\n",
        "    'N': 4,  # Handle unknown bases\n",
        "}\n",
        "\n",
        "class TimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "def timeout_handler(signum, frame):\n",
        "    raise TimeoutException(\"Function execution timed out\")\n",
        "\n",
        "class SequenceGraph:\n",
        "    \"\"\"Handles sequence encoding and graph creation on GPU.\"\"\"\n",
        "\n",
        "    def __init__(self, sequence, coords):\n",
        "        self.sequence = sequence\n",
        "        self.coords = coords\n",
        "        self.graph = self.create_graph()\n",
        "\n",
        "    def create_graph(self):\n",
        "        \"\"\"Create a PyTorch Geometric graph on the GPU.\"\"\"\n",
        "        try:\n",
        "            sequence_tensor = torch.tensor(self.sequence, dtype=torch.float32, device=\"cuda\").unsqueeze(1)\n",
        "            edge_index = torch.tensor([(i, i + 1) for i in range(len(self.sequence) - 1)], dtype=torch.long, device=\"cuda\").t().contiguous()\n",
        "            coords_tensor = torch.tensor(self.coords, dtype=torch.float32, device=\"cuda\")\n",
        "\n",
        "            return Data(x=sequence_tensor, edge_index=edge_index, pos=coords_tensor)\n",
        "        except Exception as e:\n",
        "            print(f\"Graph creation failed: {e}\")\n",
        "            return None\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load RNA sequence and structure data using cuDF\n",
        "rna_df = cudf.read_csv(\"/content/drive/MyDrive/Stanford RNA 3D Folding/Stanford_Data/train_sequences.csv\")\n",
        "\n",
        "# Convert the base_mapping dictionary into a CuPy array for the kernel\n",
        "base_mapping_array = cp.array(list(base_mapping.values()))  # Using the values from base_mapping\n",
        "\n",
        "def interpolate_missing_coordinates_gpu(coords):\n",
        "    \"\"\"Interpolates missing coordinates using KDTree on the GPU.\"\"\"\n",
        "    coords = cp.asarray(coords)\n",
        "    coords_np = cp.asnumpy(coords)\n",
        "    missing_indices = np.isnan(coords_np).any(axis=1)\n",
        "\n",
        "    if np.all(missing_indices):\n",
        "        print(\"Warning: All coordinates are missing. Imputing with mean values.\")\n",
        "        # Calculate mean of known coordinates across all sequences in your data\n",
        "        mean_coords = np.nanmean(data[['x_1', 'y_1', 'z_1']].to_numpy(), axis=0)\n",
        "        coords_np[:] = mean_coords  # Impute with mean\n",
        "        return cp.asarray(coords_np)\n",
        "\n",
        "    if not np.any(missing_indices):\n",
        "        print(\"No missing coordinates found. Returning original data.\")\n",
        "        return coords\n",
        "\n",
        "    known_indices = ~missing_indices\n",
        "    known_coords = coords_np[known_indices]\n",
        "\n",
        "    # Filter missing_coords to exclude rows with all NaNs\n",
        "    missing_coords = coords_np[missing_indices]\n",
        "    valid_missing_indices = ~np.isnan(missing_coords).all(axis=1)\n",
        "    missing_coords = missing_coords[valid_missing_indices]\n",
        "\n",
        "    if len(missing_coords) == 0:\n",
        "        print(\"All missing coordinate rows contain only NaNs. Returning original data.\")\n",
        "        return coords\n",
        "\n",
        "    tree = KDTree(known_coords)\n",
        "    _, nearest_indices = tree.query(missing_coords)  # Find nearest neighbors\n",
        "\n",
        "    for i, missing_index in enumerate(np.where(missing_indices)[0]):\n",
        "        coords_np[missing_index] = known_coords[nearest_indices[i][0]]\n",
        "\n",
        "    return cp.asarray(coords_np)\n",
        "\n",
        "\n",
        "# Function to encode sequences using base_mapping\n",
        "@cuda.jit\n",
        "def integer_encode_kernel(seq_chars, base_mapping_num_array, result):\n",
        "    idx = cuda.grid(1)\n",
        "    if idx < len(seq_chars):  # Ensure we don't exceed array bounds\n",
        "        base_char = seq_chars[idx]  # This should already be an integer\n",
        "        # Manual checking whether the base_char is within the mapping\n",
        "        if base_char == ord('A'):\n",
        "            result[idx] = base_mapping_num_array[0]  # 'A'\n",
        "        elif base_char == ord('C'):\n",
        "            result[idx] = base_mapping_num_array[1]  # 'C'\n",
        "        elif base_char == ord('G'):\n",
        "            result[idx] = base_mapping_num_array[2]  # 'G'\n",
        "        elif base_char == ord('T'):\n",
        "            result[idx] = base_mapping_num_array[3]  # 'T'\n",
        "        else:\n",
        "            result[idx] = 4  # Handle unknown bases\n",
        "\n",
        "# Function to encode sequences using base_mapping (GPU-accelerated with cuDF)\n",
        "def encode_sequence_cpu(seq):\n",
        "    \"\"\"Encodes an RNA sequence using the base_mapping on the CPU.\"\"\"\n",
        "    # Use list comprehension and the get method for CPU-based encoding\n",
        "    return [base_mapping.get(char, 4) for char in seq]\n",
        "\n",
        "def contains_n(sequence):\n",
        "    return 4 in sequence\n",
        "\n",
        "# Class to manage sequence processing\n",
        "class SequenceProcessor:\n",
        "    def __init__(self, seq, coords):\n",
        "        self.seq = seq\n",
        "        self.coords = coords\n",
        "\n",
        "    def process(self):\n",
        "        \"\"\"Encodes the sequence and interpolates missing coordinates.\"\"\"\n",
        "        encoded_seq = encode_sequence_cpu(self.seq)\n",
        "        fixed_coords = interpolate_missing_coordinates_gpu(self.coords)\n",
        "        return encoded_seq, fixed_coords\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    seq = \"AGCTNAGT\"\n",
        "    coords = np.array([\n",
        "        [1.0, 2.0, 3.0],\n",
        "        [4.0, 5.0, 6.0],\n",
        "        [np.nan, np.nan, np.nan],  # Missing coordinates\n",
        "        [7.0, 8.0, 9.0]\n",
        "    ])\n",
        "\n",
        "    processor = SequenceProcessor(seq, coords)\n",
        "    encoded_seq, fixed_coords = processor.process()\n",
        "\n",
        "    print(f\"Encoded sequence (GPU): {cp.asnumpy(encoded_seq)}\")\n",
        "    print(f\"Interpolated coordinates (GPU): {cp.asnumpy(fixed_coords)}\")"
      ],
      "metadata": {
        "id": "SNI7k2IieKnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e415d3-2196-429c-f4d4-bed46e41d708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All missing coordinate rows contain only NaNs. Returning original data.\n",
            "Encoded sequence (GPU): [0 2 1 3 4 0 2 3]\n",
            "Interpolated coordinates (GPU): [[ 1.  2.  3.]\n",
            " [ 4.  5.  6.]\n",
            " [nan nan nan]\n",
            " [ 7.  8.  9.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Quick Test"
      ],
      "metadata": {
        "id": "gW-eYAJifLjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq = \"AGCTNAGT\"\n",
        "encoded_seq = encode_sequence_cpu(seq)  # Should work now!\n",
        "print(f\"Encoded sequence (CPU): {encoded_seq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPL1Gc0Obnv8",
        "outputId": "fbccc6be-75f8-4508-9150-9de217c9c40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded sequence (CPU): [0, 2, 1, 3, 4, 0, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Load & Process RNA Data Execution (Don't Run Again Unless You Want to Wait 10 Minutes)***"
      ],
      "metadata": {
        "id": "lCwL9rZPpLbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Encoded RNA Dataframe"
      ],
      "metadata": {
        "id": "yKC1QdL3nBIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cudf\n",
        "import cupy as cp\n",
        "import rmm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.spatial import KDTree\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from numba import cuda, njit\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load RNA sequence and structure data using cuDF\n",
        "rna_df = cudf.read_csv(\"/content/drive/MyDrive/Stanford RNA 3D Folding/Stanford_Data/train_sequences.csv\")\n",
        "structure_df_cudf = cudf.read_csv(train_labels_file) # Load as cuDF DataFrame\n",
        "\n",
        "# Clean 'ID' in structure_df_cudf to match base names (remove suffixes)\n",
        "structure_df_cudf['ID'] = structure_df_cudf['ID'].str.split('_', expand=True)[0]\n",
        "\n",
        "# Apply the encoding function to the 'sequence' column on CPU using `to_pandas` and `apply`\n",
        "rna_df['encoded_sequence'] = rna_df['sequence'].to_pandas().apply(encode_sequence_cpu)\n",
        "\n",
        "# Convert the 'encoded_sequence' column back to cudf Series if needed\n",
        "rna_df['encoded_sequence'] = cudf.Series(rna_df['encoded_sequence'])\n",
        "\n",
        "# Convert the 'encoded_sequence' column to a list of lists\n",
        "encoded_sequences = rna_df['encoded_sequence'].to_arrow().to_pylist()\n",
        "\n",
        "# Print the updated DataFrame with encoded sequences (optional)\n",
        "print(\"Encoded RNA DataFrame (updated):\")\n",
        "print(rna_df.head())\n",
        "\n",
        "# Load 3D structural data using pandas (if you need pandas for any specific operations)\n",
        "# structure_df is already a pandas DataFrame, no need to convert again\n",
        "structure_df = structure_df_cudf.to_pandas() # Convert to pandas when needed\n",
        "\n",
        "# Clean both 'ID' in structure_df and 'target_id' in rna_df to match base names (remove suffixes)\n",
        "structure_df['ID'] = structure_df['ID'].str.split('_', expand=True)[0]\n",
        "rna_df['target_id'] = rna_df['target_id'].str.split('_', expand=True)[0]\n",
        "\n",
        "# Ensure merge keys are of the same data type (e.g., string)\n",
        "rna_df['target_id'] = rna_df['target_id'].astype(str)\n",
        "structure_df['ID'] = structure_df['ID'].astype(str)\n",
        "\n",
        "# Clean merge keys to ensure consistency (e.g., remove any extra characters or prefixes)\n",
        "rna_df['target_id'] = rna_df['target_id'].str.replace('_.*', '', regex=True)\n",
        "structure_df['ID'] = structure_df['ID'].str.replace('_.*', '', regex=True)\n",
        "\n",
        "# ***GROUP BY and AGGREGATE before merging***\n",
        "# Group by 'target_id' and take the first value for other columns to avoid duplicates\n",
        "# Group and aggregate before merging, including 'encoded_sequence'\n",
        "# Group and aggregate before merging, including 'encoded_sequence'\n",
        "# Merge sequence and structure data, but keep 'encoded_sequence'\n",
        "# CHANGED: Include 'encoded_sequence' in the merge\n",
        "data = rna_df.merge(structure_df_cudf, left_on=\"target_id\", right_on=\"ID\", how='inner')\n",
        "\n",
        "# Now you can group and aggregate\n",
        "data = data.groupby('target_id', as_index=False).agg(\n",
        "    {\n",
        "        'sequence': 'first',\n",
        "        'encoded_sequence': 'first',  # This will now be included\n",
        "        'temporal_cutoff': 'first',\n",
        "        'description': 'first',\n",
        "        'all_sequences': 'first',\n",
        "        # ... (other columns from structure_df_cudf)\n",
        "        'resname': 'first',\n",
        "        'resid': 'first',\n",
        "        'x_1': 'first',\n",
        "        'y_1': 'first',\n",
        "        'z_1': 'first'\n",
        "    }\n",
        ")\n",
        "structure_df_grouped = structure_df.groupby('ID').first().reset_index()\n",
        "\n",
        "# Convert to pandas\n",
        "# rna_df_grouped = rna_df_grouped.to_pandas() # Remove this conversion here\n",
        "# structure_df_grouped is already a pandas DataFrame, no need to convert\n",
        "\n",
        "# Merge sequence and structure data on cleaned and grouped IDs using pandas merge\n",
        "# CHANGED: Convert structure_df_grouped to cudf before merge\n",
        "structure_df_grouped_cudf = cudf.from_pandas(structure_df_grouped)"
      ],
      "metadata": {
        "id": "zmgRO3YepOHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3909eb1d-7ad0-4640-ba69-b924cdf01e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded RNA DataFrame (updated):\n",
            "  target_id                            sequence temporal_cutoff  \\\n",
            "0    1SCL_A       GGGUGCUCAGUACGAGAGGAACCGCACCC      1995-01-26   \n",
            "1    1RNK_A  GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU      1995-02-27   \n",
            "2    1RHT_A            GGGACUGACGAUCACGCAGUCUAU      1995-06-03   \n",
            "3    1HLX_A                GGGAUAACUUCGGUUGUCCC      1995-09-15   \n",
            "4    1HMH_E  GGCGACCCUGAUGAGGCCGAAAGGCCGAAACCGU      1995-12-07   \n",
            "\n",
            "                                         description  \\\n",
            "0               THE SARCIN-RICIN LOOP, A MODULAR RNA   \n",
            "1  THE STRUCTURE OF AN RNA PSEUDOKNOT THAT CAUSES...   \n",
            "2  24-MER RNA HAIRPIN COAT PROTEIN BINDING SITE F...   \n",
            "3  P1 HELIX NUCLEIC ACIDS (DNA/RNA) RIBONUCLEIC ACID   \n",
            "4  THREE-DIMENSIONAL STRUCTURE OF A HAMMERHEAD RI...   \n",
            "\n",
            "                                       all_sequences  \\\n",
            "0  >1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...   \n",
            "1  >1RNK_1|Chain A|RNA PSEUDOKNOT|null\\nGGCGCAGUG...   \n",
            "2  >1RHT_1|Chain A|RNA (5'-R(P*GP*GP*GP*AP*CP*UP*...   \n",
            "3  >1HLX_1|Chain A|RNA (5'-R(*GP*GP*GP*AP*UP*AP*A...   \n",
            "4  >1HMH_1|Chains A, C, E|HAMMERHEAD RIBOZYME-RNA...   \n",
            "\n",
            "                                    encoded_sequence  \n",
            "0  [2, 2, 2, 4, 2, 1, 4, 1, 0, 2, 4, 0, 1, 2, 0, ...  \n",
            "1  [2, 2, 1, 2, 1, 0, 2, 4, 2, 2, 2, 1, 4, 0, 2, ...  \n",
            "2  [2, 2, 2, 0, 1, 4, 2, 0, 1, 2, 0, 4, 1, 0, 1, ...  \n",
            "3  [2, 2, 2, 0, 4, 0, 0, 1, 4, 4, 1, 2, 2, 4, 4, ...  \n",
            "4  [2, 2, 1, 2, 0, 1, 1, 1, 4, 2, 0, 4, 2, 0, 2, ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge Dataframe"
      ],
      "metadata": {
        "id": "Zevh7AAjnKZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KDTree\n",
        "\n",
        "rna_df = cudf.read_csv(\"/content/drive/MyDrive/Stanford RNA 3D Folding/Stanford_Data/train_sequences.csv\")\n",
        "train_labels_file = \"/content/drive/MyDrive/Stanford RNA 3D Folding/Stanford_Data/train_labels.csv\"\n",
        "structure_df = cudf.read_csv(train_labels_file) # Load as cuDF DataFrame\n",
        "\n",
        "# Convert rna_df and structure_df to Dask DataFrames\n",
        "rna_df_dd = dd.from_pandas(rna_df, npartitions=4)  # Adjust number of partitions as needed\n",
        "structure_df_dd = dd.from_pandas(structure_df, npartitions=4)\n",
        "\n",
        "# Check columns in both dataframes before merge\n",
        "# Call compute() on the Dask DataFrame itself to get the columns\n",
        "print(\"RNA DataFrame columns before merge:\", rna_df_dd.columns.to_list())\n",
        "print(\"Structure DataFrame columns before merge:\", structure_df_dd.columns.to_list())\n",
        "\n",
        "# Merge sequence and structure data on cleaned and grouped IDs using Dask\n",
        "data_dd = rna_df_dd.merge(structure_df_dd, left_on=\"target_id\", right_on=\"ID\", how=\"inner\")\n",
        "\n",
        "# Check columns in the merged dataframe\n",
        "print(\"Merged DataFrame columns:\", data_dd.columns.to_list())\n",
        "\n",
        "# Convert Dask DataFrame to pandas for further processing\n",
        "data = data_dd.compute()\n",
        "\n",
        "print(f\"Shape of merged data: {data.shape}\")\n",
        "print(f\"First few rows of merged data:\\n{data.head()}\")\n",
        "\n",
        "# Identify and print sequences with unknown characters ('N') using pandas\n",
        "# Convert the 'encoded_sequence' column to a pandas Series for this operation\n",
        "# Verify if 'encoded_sequence' column exists in 'data'\n",
        "if 'encoded_sequence' in data.columns:\n",
        "    # Column exists, proceed with processing\n",
        "    unknown_sequences = data[data['encoded_sequence'].apply(lambda x: 4 in x)]\n",
        "    print(f\"Sequences with unknown characters: {unknown_sequences}\")\n",
        "else:\n",
        "    # Column does not exist, handle the situation\n",
        "    print(\"Error: 'encoded_sequence' column not found in the merged DataFrame.\")\n",
        "\n",
        "# Clean 'ID' in structure_df_cudf to match base names (remove suffixes)\n",
        "structure_df_cudf['ID'] = structure_df_cudf['ID'].str.split('_', expand=True)[0]\n",
        "\n",
        "# Apply the encoding function to the 'sequence' column on CPU using `to_pandas` and `apply`\n",
        "rna_df['encoded_sequence'] = rna_df['sequence'].to_pandas().apply(encode_sequence_cpu)\n",
        "\n",
        "# Convert the 'encoded_sequence' column back to cudf Series if needed\n",
        "rna_df['encoded_sequence'] = cudf.Series(rna_df['encoded_sequence'])\n",
        "\n",
        "# Convert into PyTorch tensors\n",
        "encoded_sequences = rna_df['encoded_sequence'].to_arrow().to_pylist()\n",
        "sequences = [torch.tensor(seq, dtype=torch.long).to(device) for seq in encoded_sequences]\n",
        "coordinates = [torch.tensor(coords, dtype=torch.float32).to(device)\n",
        "              for coords in data[['x_1', 'y_1', 'z_1']].values]\n",
        "\n",
        "print(f\"Sequences: {sequences[:5]}\")  # Display first 5 sequences\n",
        "print(f\"Coordinates: {coordinates[:5]}\")  # Display first 5 coordinates\n",
        "\n",
        "# Check for missing coordinates using pandas\n",
        "print(f\"Check for missing coordinates in structure_df: {structure_df[['x_1', 'y_1', 'z_1']].isna().sum()}\")\n",
        "\n",
        "# Now, handle the data with missing coordinates\n",
        "# Convert pandas DataFrame to NumPy array for KDTree\n",
        "known_coordinates = data[['x_1', 'y_1', 'z_1']].dropna().to_numpy()\n",
        "\n",
        "for index in data.index[data[['x_1', 'y_1', 'z_1']].isnull().any(axis=1)].to_pandas(): # Add .to_pandas() to convert to an iterable type\n",
        "    coords = data.loc[index, ['x_1', 'y_1', 'z_1']].to_numpy()\n",
        "    coords = coords.astype(np.float64)\n",
        "\n",
        "    if not np.all(np.isnan(coords)):\n",
        "        try:\n",
        "            tree = KDTree(known_coordinates)\n",
        "            missing_mask = np.isnan(coords)\n",
        "            if missing_mask.any():\n",
        "                distances, indices = tree.query(coords[missing_mask].reshape(-1, 3), k=1)\n",
        "                coords[missing_mask] = known_coordinates[indices.flatten()]\n",
        "                data.loc[index, ['x_1', 'y_1', 'z_1']] = coords  # Update DataFrame\n",
        "        except ValueError:\n",
        "            # Fallback to mean imputation if KDTree fails\n",
        "            data.loc[index, ['x_1', 'y_1', 'z_1']] = np.nanmean(known_coordinates, axis=0)\n",
        "    else:\n",
        "        # Handle case where all values in coords are NaN\n",
        "        data.loc[index, ['x_1', 'y_1', 'z_1']] = np.nanmean(known_coordinates, axis=0)"
      ],
      "metadata": {
        "id": "hx0Bqt_zm19n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Sequence Graph"
      ],
      "metadata": {
        "id": "9GGHW90_oWgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import cupy as cp\n",
        "import cudf\n",
        "import dask_cudf\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KDTree\n",
        "from dask_cuda import LocalCUDACluster\n",
        "from dask.distributed import Client\n",
        "\n",
        "# Initialize Dask with GPU support\n",
        "cluster = LocalCUDACluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "# Load the RNA DataFrame with encoded sequences\n",
        "rna_df = cudf.read_csv(\"/content/drive/MyDrive/Stanford RNA 3D Folding/Stanford_Data/train_sequences.csv\")\n",
        "rna_df['encoded_sequence'] = rna_df['sequence'].to_pandas().apply(encode_sequence_cpu)\n",
        "rna_df['encoded_sequence'] = cudf.Series(rna_df['encoded_sequence']) # Convert back to cudf Series\n",
        "\n",
        "# Load the structure DataFrame\n",
        "train_labels_file = \"/content/drive/MyDrive/Stanford RNA 3D Folding/Stanford_Data/train_labels.csv\"\n",
        "structure_df = cudf.read_csv(train_labels_file)\n",
        "\n",
        "# Convert pandas DataFrames to Dask-cuDF DataFrames\n",
        "# Use dask_cudf.from_delayed instead of dask_cudf.from_dask_dataframe\n",
        "rna_ddf = dask_cudf.from_delayed(dd.from_pandas(rna_df[['target_id']], npartitions=4).to_delayed())  # Only include 'target_id'\n",
        "structure_ddf = dask_cudf.from_delayed(dd.from_pandas(structure_df, npartitions=4).to_delayed())\n",
        "\n",
        "# Merge the DataFrames on the appropriate columns (excluding 'encoded_sequence')\n",
        "merged_ddf = rna_ddf.merge(structure_ddf, left_on=\"target_id\", right_on=\"ID\", how=\"inner\")\n",
        "\n",
        "# Convert Dask DataFrame to pandas for further processing\n",
        "merged_df = merged_ddf.compute()\n",
        "\n",
        "# Merge the encoded sequences back into the merged DataFrame\n",
        "final_df = merged_df.merge(rna_df[['target_id', 'encoded_sequence']], on='target_id', how='left')\n",
        "\n",
        "\n",
        "# Define a function to create graph data for a single row (without using SequenceGraph class)\n",
        "def create_graph_data_for_row(row):\n",
        "    \"\"\"Create PyTorch Geometric graph data for a single row.\"\"\"\n",
        "    # ... (Your existing code to get encoded_seq and coords)\n",
        "\n",
        "    # ***CHANGED: Get encoded_seq and coords from the row***\n",
        "    encoded_seq = row['encoded_sequence']\n",
        "    coords = row[['x_1', 'y_1', 'z_1']].values\n",
        "\n",
        "    # Create the graph data using torch.tensor on the CPU\n",
        "    sequence_tensor = torch.tensor(encoded_seq, dtype=torch.float32).unsqueeze(1)\n",
        "    edge_index = torch.tensor([(i, i + 1) for i in range(len(encoded_seq) - 1)], dtype=torch.long).t().contiguous() if len(encoded_seq) > 1 else torch.empty((2, 0), dtype=torch.long)\n",
        "    coords_tensor = torch.tensor(coords, dtype=torch.float32)\n",
        "\n",
        "    # Create the Data object on the CPU\n",
        "    graph_data = Data(x=sequence_tensor, edge_index=edge_index, pos=coords_tensor)\n",
        "\n",
        "    # Move the Data object to the GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "        graph_data = graph_data.to(\"cuda\")\n",
        "\n",
        "    return graph_data\n",
        "\n",
        "# Apply the function to create graph data\n",
        "graph_data = final_df.to_pandas().apply(create_graph_data_for_row, axis=1)\n",
        "graph_data = graph_data.values.tolist() # Convert to a regular list\n",
        "\n",
        "# Convert sequences and coordinates to PyTorch tensors\n",
        "# Changed this to get encoded_sequence from the graph data\n",
        "sequences = [torch.tensor(graph.x.cpu().numpy(), dtype=torch.long).to(device) for graph in graph_data]\n",
        "coordinates = [torch.tensor(graph.pos.cpu().numpy(), dtype=torch.float32).to(device) for graph in graph_data]\n",
        "\n",
        "# Check for missing coordinates\n",
        "missing_coords = [i for i, coords in enumerate(coordinates) if coords.isnull().any()]\n",
        "\n",
        "# Handle missing coordinates using KDTree\n",
        "known_coordinates = data[['x_1', 'y_1', 'z_1']].dropna().to_numpy()\n",
        "\n",
        "for index in data.index[data[['x_1', 'y_1', 'z_1']].isnull().any(axis=1)].to_pandas(): # Add .to_pandas() to convert to an iterable type\n",
        "    coords = data.loc[index, ['x_1', 'y_1', 'z_1']].to_numpy()\n",
        "    coords = coords.astype(np.float64)\n",
        "\n",
        "    if not np.all(np.isnan(coords)):\n",
        "        try:\n",
        "            tree = KDTree(known_coordinates)\n",
        "            missing_mask = np.isnan(coords)\n",
        "            if missing_mask.any():\n",
        "                distances, indices = tree.query(coords[missing_mask].reshape(-1, 3), k=1)\n",
        "                coords[missing_mask] = known_coordinates[indices.flatten()]\n",
        "                data.loc[index, ['x_1', 'y_1', 'z_1']] = coords  # Update DataFrame\n",
        "        except ValueError:\n",
        "            # Fallback to mean imputation if KDTree fails\n",
        "            data.loc[index, ['x_1', 'y_1', 'z_1']] = np.nanmean(known_coordinates, axis=0)\n",
        "    else:\n",
        "        # Handle case where all values in coords are NaN\n",
        "        data.loc[index, ['x_1', 'y_1', 'z_1']] = np.nanmean(known_coordinates, axis=0)\n",
        "\n",
        "for i in missing_coords:\n",
        "    coords = coordinates[i]\n",
        "    if coords.isnull().any():\n",
        "        distances, indices = tree.query(coords[coords.isnull()].reshape(-1, 3), k=1)\n",
        "        coords[coords.isnull()] = known_coordinates[indices.flatten()]"
      ],
      "metadata": {
        "id": "9f6yeAEXkPcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Models***"
      ],
      "metadata": {
        "id": "godrM1TPy6XK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNN For Spatial Interactions"
      ],
      "metadata": {
        "id": "g5HMzI4jpPrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GvbEroV7pSMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer for Sequence Depencencies (Lightweight Model)"
      ],
      "metadata": {
        "id": "U-9MrK92pUY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size=4, hidden_dim=128):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
        "        self.transformer = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.fc = nn.Linear(768, hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer(inputs_embeds=x).last_hidden_state.mean(dim=1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "6KkGYbqCpTky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine GNN & Transformer"
      ],
      "metadata": {
        "id": "QJdxlv2opZxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, gnn_hidden=128, transformer_hidden=128, cnn_out=128, output_dim=3):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.gnn = GNNModel(input_dim=1, hidden_dim=gnn_hidden, output_dim=gnn_hidden)\n",
        "        self.transformer = TransformerModel(vocab_size=4, hidden_dim=transformer_hidden)\n",
        "        self.cnn3d = CNN3DModel(in_channels=1, out_dim=cnn_out)\n",
        "        self.fc = nn.Linear(gnn_hidden + transformer_hidden + cnn_out, output_dim)\n",
        "\n",
        "    def forward(self, graph, sequence, structure_3d):\n",
        "        gnn_out = self.gnn(graph.x, graph.edge_index)\n",
        "        gnn_out = global_mean_pool(gnn_out, batch=None)\n",
        "\n",
        "        transformer_out = self.transformer(sequence)\n",
        "\n",
        "        cnn_out = self.cnn3d(structure_3d)\n",
        "\n",
        "        combined = torch.cat((gnn_out, transformer_out, cnn_out), dim=1)\n",
        "        return self.fc(combined)"
      ],
      "metadata": {
        "id": "amrnhRCLpZkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training GNN"
      ],
      "metadata": {
        "id": "zLYr208Vpd9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Train and Evaluate GNN\n",
        "gnn_model = GNNModel(input_dim=1, hidden_dim=128, output_dim=3).to(device) # Output dim should be 3 for coordinates\n",
        "gnn_optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for i in range(len(graph_data)):\n",
        "        graph, structure_3d = graph_data[i].to(device), coordinates[i].to(device)\n",
        "        gnn_optimizer.zero_grad()\n",
        "        predicted_coords = gnn_model(graph.x, graph.edge_index)  # GNN forward pass\n",
        "        # Apply global_mean_pool to get a single prediction per graph\n",
        "        predicted_coords = global_mean_pool(predicted_coords, batch=None)\n",
        "        loss = rmsd_loss(predicted_coords, structure_3d)\n",
        "        loss.backward()\n",
        "        gnn_optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"GNN - Epoch {epoch+1}, RMSD Loss: {total_loss / len(graph_data)}\")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "# Load the saved model\n",
        "loaded_model = GNNModel().to(device)\n",
        "loaded_model.load_state_dict(torch.load(\"/content/drive/MyDrive/Stanford RNA 3D Folding\"))\n",
        "loaded_model.eval()  # Set to evaluation mode"
      ],
      "metadata": {
        "id": "hCG0FhompeLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Transformers"
      ],
      "metadata": {
        "id": "pJ99yDAOyqw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Train and Evaluate Transformer\n",
        "transformer_model = TransformerModel(vocab_size=4, hidden_dim=128).to(device)\n",
        "transformer_optimizer = torch.optim.Adam(transformer_model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for i in range(len(graph_data)):\n",
        "        sequence, structure_3d = sequences[i].to(device), coordinates[i].to(device)\n",
        "        transformer_optimizer.zero_grad()\n",
        "        predicted_coords = transformer_model(sequence.unsqueeze(0)) # Transformer forward pass\n",
        "        loss = rmsd_loss(predicted_coords, structure_3d)\n",
        "        loss.backward()\n",
        "        transformer_optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Transformer - Epoch {epoch+1}, RMSD Loss: {total_loss / len(graph_data)}\")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "# Load the saved model\n",
        "loaded_model = TransformerModel().to(device)\n",
        "loaded_model.load_state_dict(torch.load(\"/content/drive/MyDrive/Stanford RNA 3D Folding\"))\n",
        "loaded_model.eval()  # Set to evaluation mode"
      ],
      "metadata": {
        "id": "OAX9q39kyqh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid GNN & Transformers Training"
      ],
      "metadata": {
        "id": "EJjjpPMKzDWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = HybridModel().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 50  # Adjust epochs as needed\n",
        "best_loss = float('inf')  # Initialize best loss for saving the best model\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i in range(len(graph_data)):\n",
        "        graph, sequence, structure_3d = graph_data[i].to(device), sequences[i].to(device), coordinates[i].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        predicted_coords = model(graph, sequence.unsqueeze(0), structure_3d.unsqueeze(0).unsqueeze(0)) # Add extra dimension for CNN3D\n",
        "\n",
        "        # Compute RMSD loss\n",
        "        loss = rmsd_loss(predicted_coords, structure_3d)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print average loss per epoch\n",
        "    avg_loss = total_loss / len(graph_data)\n",
        "    print(f\"Epoch {epoch+1}, RMSD Loss: {avg_loss}\")\n",
        "\n",
        "    # Save the best model\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        # Create a directory for saving the model if it doesn't exist\n",
        "        os.makedirs(\"saved_models\", exist_ok=True)\n",
        "        torch.save(model.state_dict(), \"saved_models/best_hybrid_model.pth\")\n",
        "        print(f\"Saved best model with loss {best_loss:.4f} to saved_models/best_hybrid_model.pth\")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "# Load the saved model\n",
        "loaded_model = HybridModel().to(device)\n",
        "loaded_model.load_state_dict(torch.load(\"/content/drive/MyDrive/Stanford RNA 3D Folding\"))\n",
        "loaded_model.eval()  # Set to evaluation mode"
      ],
      "metadata": {
        "id": "C7xPsIwPzDjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSD (Roof Mean Square Deviation) Training Loss"
      ],
      "metadata": {
        "id": "-VNAgRwRph3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmsd_loss(predicted_coords, true_coords):\n",
        "    \"\"\"\n",
        "    Compute the RMSD between predicted 3D coordinates and true coordinates.\n",
        "\n",
        "    Args:\n",
        "    predicted_coords (torch.Tensor): Predicted 3D coordinates (shape: [batch_size, 3])\n",
        "    true_coords (torch.Tensor): True 3D coordinates (shape: [batch_size, 3])\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: RMSD loss value\n",
        "    \"\"\"\n",
        "    # Compute squared differences between predicted and true coordinates\n",
        "    squared_diff = torch.square(predicted_coords - true_coords)\n",
        "\n",
        "    # Compute RMSD\n",
        "    rmsd = torch.sqrt(torch.mean(squared_diff))\n",
        "    return rmsd"
      ],
      "metadata": {
        "id": "0f7WU8GNpkLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating Model Performance"
      ],
      "metadata": {
        "id": "IzACi_WGpmGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Compute RMSD (Root Mean Square Deviation)\n",
        "def compute_rmsd(predicted_coords, true_coords):\n",
        "    \"\"\"\n",
        "    Calculate RMSD between predicted and true 3D coordinates.\n",
        "    \"\"\"\n",
        "    diff = predicted_coords - true_coords\n",
        "    squared_diff = np.square(diff)\n",
        "    mean_squared_diff = np.mean(squared_diff)\n",
        "    rmsd = np.sqrt(mean_squared_diff)\n",
        "    return rmsd\n",
        "\n",
        "# 2. Compute TM-score (simplified version)\n",
        "def compute_tm_score(predicted_coords, true_coords, d0=1.24 * (len(true_coords) ** (1/3)) - 1.8):\n",
        "    \"\"\"\n",
        "    Compute a simplified TM-score.\n",
        "    d0 is a scaling factor dependent on protein length (or RNA length in our case).\n",
        "    \"\"\"\n",
        "    distances = np.linalg.norm(predicted_coords - true_coords, axis=1)\n",
        "    tm_score = np.sum(1 / (1 + (distances / d0) ** 2)) / len(true_coords)\n",
        "    return tm_score\n",
        "\n",
        "# 3. Compute GDT-TS (Global Distance Test - Total Score)\n",
        "def compute_gdt_ts(predicted_coords, true_coords, thresholds=[1, 2, 4, 8]):\n",
        "    \"\"\"\n",
        "    Compute GDT-TS score, which measures the fraction of residues within certain distance thresholds.\n",
        "    \"\"\"\n",
        "    distances = np.linalg.norm(predicted_coords - true_coords, axis=1)\n",
        "    gdt_scores = [np.mean(distances < t) for t in thresholds]\n",
        "    gdt_ts = np.mean(gdt_scores)\n",
        "    return gdt_ts\n",
        "\n",
        "# Sample Test Data\n",
        "true_coords = np.array([[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3]])  # True 3D positions\n",
        "predicted_coords = np.array([[0, 0.1, 0], [1.1, 1, 1], [2, 2.2, 2], [3, 3, 3.1]])  # Predicted positions\n",
        "\n",
        "# Evaluate Model Performance\n",
        "rmsd_value = compute_rmsd(predicted_coords, true_coords)\n",
        "tm_score_value = compute_tm_score(predicted_coords, true_coords)\n",
        "gdt_ts_value = compute_gdt_ts(predicted_coords, true_coords)\n",
        "\n",
        "# Print results\n",
        "print(f\"RMSD: {rmsd_value:.4f}\")\n",
        "print(f\"TM-score: {tm_score_value:.4f}\")\n",
        "print(f\"GDT-TS: {gdt_ts_value:.4f}\")"
      ],
      "metadata": {
        "id": "6UsrsmdWpl56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "52be9f42-bdea-4c31-a6c5-5cd0181b5e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'true_coords' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c90cc25146e9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 2. Compute TM-score (simplified version)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_tm_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.24\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_coords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \"\"\"\n\u001b[1;32m     15\u001b[0m     \u001b[0mCompute\u001b[0m \u001b[0ma\u001b[0m \u001b[0msimplified\u001b[0m \u001b[0mTM\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'true_coords' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam Training Optimizer"
      ],
      "metadata": {
        "id": "rh0syKsTprCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up optimizer with weight decay (L2 regularization)\n",
        "learning_rate = 0.001\n",
        "weight_decay = 1e-5  # Regularization strength (adjust if needed)\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "# Set up learning rate scheduler (decay every 10 epochs)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)  # Halve learning rate every 10 epochs\n",
        "\n",
        "# Training loop\n",
        "epochs = 50  # Adjust based on your dataset size\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for i in range(len(graph_data)):\n",
        "        graph, sequence, structure_3d = graph_data[i].to(device), sequences[i].to(device), coordinates[i].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        predicted_coords = model(graph, sequence.unsqueeze(0), structure_3d.unsqueeze(0))\n",
        "\n",
        "        # Compute RMSD loss\n",
        "        loss = rmsd_loss(predicted_coords, structure_3d.unsqueeze(0))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Step scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Print average loss per epoch\n",
        "    print(f\"Epoch {epoch+1}, RMSD Loss: {total_loss / len(graph_data)}\")\n",
        "\n",
        "    # Optionally, print learning rate at each epoch\n",
        "    print(f\"Learning Rate at Epoch {epoch+1}: {scheduler.get_last_lr()[0]}\")"
      ],
      "metadata": {
        "id": "xeAw0cDPprNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNA/LSTM Model (Long Short Term Memory)"
      ],
      "metadata": {
        "id": "h5uHKNyHpwKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Define RNA bases\n",
        "RNA_BASES = ['A', 'U', 'G', 'C']\n",
        "\n",
        "# -------------------- DATA AUGMENTATION FUNCTIONS --------------------\n",
        "\n",
        "def mutate_rna(sequence, mutation_rate=0.1):\n",
        "    \"\"\" Introduce random mutations while keeping valid RNA bases. \"\"\"\n",
        "    return ''.join([\n",
        "        base if random.random() > mutation_rate else random.choice(RNA_BASES)\n",
        "        for base in sequence\n",
        "    ])\n",
        "\n",
        "def shuffle_rna(sequence, window_size=5):\n",
        "    \"\"\" Shuffle small segments to introduce sequence variability. \"\"\"\n",
        "    seq_list = list(sequence)\n",
        "    for i in range(0, len(seq_list) - window_size, window_size):\n",
        "        random.shuffle(seq_list[i:i+window_size])\n",
        "    return ''.join(seq_list)\n",
        "\n",
        "def perturb_3d_coordinates(coords, noise_level=0.5):\n",
        "    \"\"\" Add random noise to 3D atomic coordinates. \"\"\"\n",
        "    noise = np.random.normal(scale=noise_level, size=coords.shape)\n",
        "    return coords + noise\n",
        "\n",
        "# -------------------- ONE-HOT ENCODING --------------------\n",
        "\n",
        "def one_hot_encode(seq):\n",
        "    \"\"\" Convert RNA sequence into a one-hot encoded matrix. \"\"\"\n",
        "    mapping = {'A': [1, 0, 0, 0], 'U': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'C': [0, 0, 0, 1]}\n",
        "    return np.array([mapping[base] for base in seq])\n",
        "\n",
        "# -------------------- LSTM MODEL --------------------\n",
        "\n",
        "from Bio.PDB import PDBIO, Structure, Model, Chain, Residue, Atom\n",
        "\n",
        "def save_pdb(pred_coords, output_file=\"predicted_structure.pdb\"):\n",
        "    \"\"\" Save predicted 3D coordinates as a PDB file. \"\"\"\n",
        "    structure = Structure.Structure(\"RNA\")\n",
        "    model = Model.Model(0)\n",
        "    chain = Chain.Chain(\"A\")\n",
        "\n",
        "    for i, (x, y, z) in enumerate(pred_coords.detach().numpy()):\n",
        "        residue = Residue.Residue((\" \", i, \" \"), \"A\", \" \")\n",
        "        atom = Atom.Atom(\"P\", (x, y, z), 1.0, 1.0, \" \", \"P\", i, \"P\")\n",
        "        residue.add(atom)\n",
        "        chain.add(residue)\n",
        "\n",
        "    model.add(chain)\n",
        "    structure.add(model)\n",
        "\n",
        "    io = PDBIO()\n",
        "    io.set_structure(structure)\n",
        "    io.save(output_file)\n",
        "\n",
        "# Call this function after model inference\n",
        "save_pdb(predicted_coords, \"rna_prediction.pdb\")\n",
        "\n",
        "class RNASequenceModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNASequenceModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)  # Output predicts secondary structure\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)  # x: (batch_size, seq_length, input_size)\n",
        "        out = self.fc(lstm_out[:, -1, :])  # Use last time step for prediction\n",
        "        return out\n",
        "\n",
        "# -------------------- MODEL INITIALIZATION --------------------\n",
        "\n",
        "input_size = 4  # One-hot encoding for A, U, G, C\n",
        "hidden_size = 128\n",
        "output_size = 1  # Predicts secondary structure (e.g., binary classification)\n",
        "\n",
        "model = RNASequenceModel(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()  # Mean Squared Error Loss for regression tasks\n",
        "\n",
        "# -------------------- TRAINING DATA --------------------\n",
        "\n",
        "rna_sequence = \"AUGCGAUCGUAGC\"  # Example sequence\n",
        "target_structure = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]  # Example base-pairing binary labels\n",
        "\n",
        "# Apply data augmentation\n",
        "augmented_seq = mutate_rna(rna_sequence, mutation_rate=0.2)\n",
        "augmented_seq = shuffle_rna(augmented_seq, window_size=4)\n",
        "\n",
        "# Encode the RNA sequence\n",
        "encoded_seq = one_hot_encode(augmented_seq)\n",
        "encoded_seq = torch.tensor(encoded_seq, dtype=torch.float32).unsqueeze(0)  # Shape: (1, seq_length, input_size)\n",
        "target_structure = torch.tensor(target_structure, dtype=torch.float32).unsqueeze(0)  # Shape: (1, seq_length)\n",
        "\n",
        "# -------------------- TRAINING LOOP --------------------\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(encoded_seq)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_fn(output, target_structure)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "PAvjng5fpwdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Fine Tuning"
      ],
      "metadata": {
        "id": "sxtOKvyFp2Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- 1. DATA AUGMENTATION --------------------\n",
        "\n",
        "def mutate_sequence(seq, mutation_rate=0.1):\n",
        "    \"\"\" Randomly mutate the RNA sequence to introduce variability. \"\"\"\n",
        "    bases = ['A', 'U', 'G', 'C']\n",
        "    seq_list = list(seq)\n",
        "    for i in range(len(seq_list)):\n",
        "        if np.random.rand() < mutation_rate:\n",
        "            seq_list[i] = np.random.choice(bases)\n",
        "    return \"\".join(seq_list)\n",
        "\n",
        "# -------------------- 2. ONE-HOT ENCODING --------------------\n",
        "\n",
        "def one_hot_encode(seq):\n",
        "    \"\"\" Convert RNA sequence into one-hot encoded format. \"\"\"\n",
        "    mapping = {'A': [1, 0, 0, 0], 'U': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'C': [0, 0, 0, 1]}\n",
        "    return np.array([mapping[base] for base in seq])\n",
        "\n",
        "# -------------------- 3. FEATURE EXTRACTION (TRANSFER LEARNING) --------------------\n",
        "\n",
        "esm_model = EsmModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
        "esm_tokenizer = EsmTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
        "\n",
        "def extract_features(sequence):\n",
        "    \"\"\" Extract RNA sequence embeddings using ESM-2 (transfer learning). \"\"\"\n",
        "    inputs = esm_tokenizer(sequence, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = esm_model(**inputs)\n",
        "    return outputs.last_hidden_state.squeeze(0)  # Shape: (seq_length, embedding_dim)\n",
        "\n",
        "# -------------------- 4. DATASET CLASS --------------------\n",
        "\n",
        "class RNA3DDataset(Dataset):\n",
        "    def __init__(self, rna_sequence, secondary_structure, atom_coordinates):\n",
        "        self.rna_sequence = rna_sequence\n",
        "        self.secondary_structure = secondary_structure\n",
        "        self.atom_coordinates = atom_coordinates\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.rna_sequence)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mutated_seq = mutate_sequence(self.rna_sequence)  # Apply data augmentation\n",
        "        seq_features = extract_features(mutated_seq)  # Use transfer learning\n",
        "        sec_structure = self.secondary_structure[idx]\n",
        "        coords = self.atom_coordinates[idx]\n",
        "        return seq_features, torch.tensor(sec_structure, dtype=torch.float32), torch.tensor(coords, dtype=torch.float32)\n",
        "\n",
        "# -------------------- 5. MODEL: TRANSFORMER + LSTM --------------------\n",
        "\n",
        "class RNA3DModel(nn.Module):\n",
        "    def __init__(self, input_size=320, hidden_size=128, output_size=3):\n",
        "        super(RNA3DModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size, 64)\n",
        "        self.fc2 = nn.Linear(64, output_size)  # Predicts (X, Y, Z) coordinates\n",
        "\n",
        "    def forward(self, seq_input, sec_input):\n",
        "        lstm_out, _ = self.lstm(seq_input)\n",
        "        x = self.fc1(lstm_out[:, -1, :])\n",
        "        x = torch.relu(x)\n",
        "        coords = self.fc2(x)\n",
        "        return coords\n",
        "\n",
        "# -------------------- 6. LOSS FUNCTION --------------------\n",
        "\n",
        "def rmsd_loss(pred_coords, true_coords):\n",
        "    \"\"\" Compute RMSD loss for 3D coordinates. \"\"\"\n",
        "    return torch.sqrt(torch.mean((pred_coords - true_coords) ** 2))\n",
        "\n",
        "# -------------------- 7. TRAINING --------------------\n",
        "\n",
        "# Sample Data (for demo)\n",
        "rna_sequence = \"AUGCGAUCGUAGC\"\n",
        "secondary_structure = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
        "atom_coordinates = np.random.rand(len(rna_sequence), 3)  # Simulated 3D coordinates\n",
        "\n",
        "# DataLoader\n",
        "dataset = RNA3DDataset(rna_sequence, secondary_structure, atom_coordinates)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Model, Optimizer\n",
        "model = RNA3DModel()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for seq_input, sec_input, true_coords in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        pred_coords = model(seq_input, sec_input)\n",
        "        loss = rmsd_loss(pred_coords, true_coords)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# -------------------- 8. TESTING --------------------\n",
        "\n",
        "sample_features = extract_features(rna_sequence).unsqueeze(0)\n",
        "predicted_coords = model(sample_features, torch.tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1], dtype=torch.float32).unsqueeze(0))\n",
        "\n",
        "print(\"Predicted 3D coordinates:\", predicted_coords)"
      ],
      "metadata": {
        "id": "D2KtBqwKp2TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post Prediction Energy Minimization"
      ],
      "metadata": {
        "id": "ON8qG4IAp6Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def energy_minimize_pdb(pdb_file, output_file=\"minimized.pdb\"):\n",
        "    \"\"\"\n",
        "    Perform energy minimization on an RNA structure using OpenMM.\n",
        "\n",
        "    Args:\n",
        "    - pdb_file (str): Path to the input PDB file.\n",
        "    - output_file (str): Path to save the minimized structure.\n",
        "\n",
        "    Returns:\n",
        "    - Minimized structure saved in PDB format.\n",
        "    \"\"\"\n",
        "    # Load RNA structure from PDB\n",
        "    pdb = app.PDBFile(pdb_file)\n",
        "    forcefield = app.ForceField(\"amber99sb.xml\", \"amber99_obc.xml\")\n",
        "\n",
        "    # Create OpenMM system\n",
        "    system = forcefield.createSystem(\n",
        "        pdb.topology, nonbondedMethod=app.NoCutoff, constraints=app.HBonds\n",
        "    )\n",
        "\n",
        "    # Define integrator for energy minimization\n",
        "    integrator = LangevinIntegrator(300 * omm_unit.kelvin, 1 / omm_unit.picosecond, 0.002 * omm_unit.picoseconds)\n",
        "\n",
        "    # Use CPU or GPU for simulation\n",
        "    platform = Platform.getPlatformByName(\"CPU\")  # Change to \"CUDA\" for GPU\n",
        "\n",
        "    # Set up simulation\n",
        "    simulation = app.Simulation(pdb.topology, system, integrator, platform)\n",
        "    simulation.context.setPositions(pdb.positions)\n",
        "\n",
        "    # Energy minimization\n",
        "    print(\"Minimizing energy...\")\n",
        "    simulation.minimizeEnergy()\n",
        "\n",
        "    # Save minimized structure\n",
        "    positions = simulation.context.getState(getPositions=True).getPositions()\n",
        "    with open(output_file, \"w\") as f:\n",
        "        app.PDBFile.writeFile(pdb.topology, positions, f)\n",
        "\n",
        "    print(f\"Minimized structure saved to {output_file}\")\n",
        "\n",
        "# Example: Run energy minimization on an RNA structure\n",
        "pdb_file = \"predicted_rna.pdb\"  # Replace with actual predicted structure\n",
        "energy_minimize_pdb(pdb_file)"
      ],
      "metadata": {
        "id": "Js9EAZdip6eW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "c808557c-ce98-4f2c-f450-4c7ae8ba06ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'predicted_rna.pdb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-437119306ab3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Example: Run energy minimization on an RNA structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mpdb_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"predicted_rna.pdb\"\u001b[0m  \u001b[0;31m# Replace with actual predicted structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0menergy_minimize_pdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-437119306ab3>\u001b[0m in \u001b[0;36menergy_minimize_pdb\u001b[0;34m(pdb_file, output_file)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \"\"\"\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Load RNA structure from PDB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPDBFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mforcefield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mForceField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"amber99sb.xml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"amber99_obc.xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openmm/app/pdbfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, extraParticleIdentifier)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mown_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0minputfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mown_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mpdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdbStructure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_all_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextraParticleIdentifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextraParticleIdentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'predicted_rna.pdb'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine Tuned Model With Simulation Learning"
      ],
      "metadata": {
        "id": "c6anC3Zqp-fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CorrectionModel(nn.Module):\n",
        "    def __init__(self, input_dim=3, hidden_dim=64, output_dim=3):\n",
        "        super(CorrectionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "correction_model = CorrectionModel()\n",
        "optimizer = optim.Adam(correction_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "tZlcieybp-sI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}